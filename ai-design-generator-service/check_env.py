import os
import sys
import torch

print("=" * 60)
print("V√âRIFICATION DE L'ENVIRONNEMENT PYTHON/PYTORCH")
print("=" * 60)

print("\nüìÅ Informations syst√®me:")
print(f"   Python: {sys.version}")
print(f"   R√©pertoire courant: {os.getcwd()}")

print("\nüîß Variables d'environnement importantes:")
env_vars = [
    "CUDA_VISIBLE_DEVICES",
    "PYTORCH_ENABLE_MPS_FALLBACK", 
    "PYTORCH_DIRECTML_DISABLE",
    "PATH"
]

for var in env_vars:
    value = os.environ.get(var, "Non d√©fini")
    if var == "PATH":
        print(f"   {var}: [pr√©sent, longueur: {len(value)}]")
    else:
        print(f"   {var}: {value}")

print("\nüíª Configuration PyTorch:")
print(f"   Version PyTorch: {torch.__version__}")
print(f"   Version CUDA: {torch.version.cuda if hasattr(torch.version, 'cuda') else 'N/A'}")
print(f"   CUDA disponible: {torch.cuda.is_available()}")
print(f"   Nombre de GPUs CUDA: {torch.cuda.device_count() if torch.cuda.is_available() else 0}")

print("\nüéØ Devices disponibles:")
print(f"   CPU: {torch.device('cpu')}")

try:
    import torch_directml
    print(f"   DirectML disponible: OUI")
    print(f"   DirectML device: {torch_directml.device()}")
    print(f"   Nombre de devices DirectML: {torch_directml.device_count()}")
except ImportError:
    print(f"   DirectML disponible: NON (non install√©)")
except Exception as e:
    print(f"   DirectML erreur: {str(e)[:100]}")

try:
    if hasattr(torch.backends, 'mps') and torch.backends.mps.is_available():
        print(f"   MPS (Mac) disponible: OUI")
    else:
        print(f"   MPS (Mac) disponible: NON")
except:
    print(f"   MPS (Mac): erreur de v√©rification")

print("\nüß™ Test cr√©ation de tensors:")
try:
    x_cpu = torch.randn(2, 3, device='cpu')
    print(f"   Tensor CPU cr√©√©: {x_cpu.device}, dtype: {x_cpu.dtype}")
    
    y_cpu = torch.randn(3, 2, device='cpu')
    z_cpu = x_cpu @ y_cpu
    print(f"   Multiplication CPU r√©ussie: {z_cpu.shape}")
    
    try:
        import torch_directml
        dml = torch_directml.device()
        x_dml = torch.randn(2, 3, device=dml)
        print(f"   Tensor DirectML cr√©√©: {x_dml.device}, dtype: {x_dml.dtype}")
    except:
        pass
        
except Exception as e:
    print(f"   ‚ùå Erreur lors des tests: {e}")

print("\nüì¶ Packages install√©s:")
try:
    import pkg_resources
    packages = ["torch", "torchvision", "torchaudio", "diffusers", "transformers", "torch-directml"]
    for pkg in packages:
        try:
            version = pkg_resources.get_distribution(pkg).version
            print(f"   {pkg}: {version}")
        except:
            print(f"   {pkg}: NON INSTALL√â")
except:
    print("   Impossible de v√©rifier les packages")

print("\n" + "=" * 60)
print("ANALYSE:")
print("=" * 60)

issues = []
if torch.cuda.is_available():
    print("‚ö†Ô∏è  CUDA est disponible - risque de conflit avec DirectML/CPU")
    issues.append("CUDA activ√©")

try:
    import torch_directml
    print("‚ö†Ô∏è  DirectML est install√© - peut causer des conflits")
    issues.append("DirectML install√©")
except:
    print("‚úÖ DirectML non install√© - bon pour CPU pur")

if os.environ.get("CUDA_VISIBLE_DEVICES") != "-1":
    print("‚ùå CUDA_VISIBLE_DEVICES n'est pas d√©fini √† '-1'")
    issues.append("CUDA_VISIBLE_DEVICES incorrect")
else:
    print("‚úÖ CUDA_VISIBLE_DEVICES = '-1' (CUDA d√©sactiv√©)")

if issues:
    print(f"\nüö® PROBL√àMES D√âTECT√âS: {len(issues)}")
    for i, issue in enumerate(issues, 1):
        print(f"   {i}. {issue}")
    print("\nüí° RECOMMANDATIONS:")
    print("   1. Assurez-vous que CUDA_VISIBLE_DEVICES=-1")
    print("   2. D√©sinstallez torch-directml: pip uninstall torch-directml")
    print("   3. Forcez CPU dans votre code: torch.set_default_device('cpu')")
else:
    print("\n‚úÖ Environnement correct pour CPU!")

print("\n" + "=" * 60)